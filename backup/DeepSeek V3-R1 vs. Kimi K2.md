<img width="4096" height="2142" alt="Image" src="https://github.com/user-attachments/assets/edfb843f-0e70-4d71-bb88-ec963ea0a412" />

Kimi-K2 与 DeepSeek-R1 架构对比，相比较下 Kimi-k2 增加了专家数量，减少了注意力头的数量。

这么设计的好处是，专家数量多无疑知识多，能记住更多东西，在知识广度上表现很好。而减少注意力头则能显著减少显存开销，另外过多的注意力头有时会学习到冗余或过于相似的注意力模式。通过减少头的数量，模型可能被迫让每个头学习到更独特、更关键的特征，这可能有助于防止过拟合，提升模型的泛化能力。