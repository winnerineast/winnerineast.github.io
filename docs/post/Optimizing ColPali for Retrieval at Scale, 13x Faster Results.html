<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    
    <link rel="icon" href="https://github.githubassets.com/favicons/favicon.svg"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="
ColPali is a fascinating leap in document retrieval. Its precision in handling visually rich PDFs is phenomenal, but scaling it to handle real-world datasets comes with its share of computational challenges.

Here’s how we solved these challenges to make ColPali 13x faster without sacrificing the precision it’s known for.

## [](https://qdrant.tech/blog/colpali-qdrant-optimization/#the-scaling-dilemma)The Scaling Dilemma

ColPali generates **1,030 vectors for just one page of a PDF.** While this is manageable for small-scale tasks, in a real-world production setting where you may need to store hundreds od thousands of PDFs, the challenge of scaling becomes significant.

Consider this scenario:

- **Dataset Size:** 20,000 PDF pages.
- **Number of Vectors:** Each page generates ~1,000 vectors of 128 dimensions.

The total number of comparisons is calculated as:

1,000⋅1,000⋅20,000⋅128=2.56×1012 comparisons!

That’s trillions of comparisons needed to build the index. Even advanced indexing algorithms like **HNSW** struggle with this scale, as computational costs grow quadratically with amount of multivectors per page.

We turned to a hybrid optimization strategy combining **pooling** (to reduce computational overhead) and **reranking** (to preserve accuracy).

Before we go any deeper, watch our [Webinar video](https://www.youtube.com/live/_h6SN1WwnLs?si=n8gwiIjJ5dnfucXC) for the full demo walkthrough.

For those eager to explore, the [codebase is available here](https://github.com/qdrant/demo-colpali-optimized).

## [](https://qdrant.tech/blog/colpali-qdrant-optimization/#two-stage-retrieval-process)Two-Stage Retrieval Process

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#pooling)Pooling

Pooling is well-known in machine learning as a way to compress data while keeping important information. For ColPali, we reduced 1,030 vectors per page to just 38 vectors by pooling rows in the document’s 32x32 grid.

![](https://qdrant.tech/blog/colpali-optimization/rows.png)

Max and mean pooling are the two most popular types, so we decided to test both approaches on the rows of the grid. Likewise, we could apply pooling on columns, which we plan to explore in the future.

- **Mean Pooling:** Averages values across rows.
- **Max Pooling:** Selects the maximum value for each feature.

32 vectors represent the pooled rows, while 6 vectors encode contextual information derived from ColPali’s special tokens (e.g., for the beginning of the sequence, and task-specific instructions like “Describe the image”).

For our experiments, we chose to preserve these 6 additional vectors.

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#the-colpali-as-a-reranker-experiment)The “ColPali as a Reranker” Experiment

Pooling drastically reduces retrieval costs, but there’s a risk of losing fine-grained precision. To address this, we implemented a **two-stage retrieval system**, where embeddings generated with ColPali were max/mean pooled by grid rows to create lightweight vectors for the initial retrieval stage, followed by reranking with the original high-resolution embeddings:

1. **Pooled Retrieval:** Quickly retrieves the top 200 candidates using lightweight pooled embeddings.
2. **Full Reranking:** Refines these candidates using the original, high-resolution embeddings, delivering the final top 20 results.

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#implementation)Implementation

We created a custom dataset with over 20,000 unique PDF pages by merging:

- **ViDoRe Benchmark:** Designed for PDF documents retrieval evaluation.
- **UFO Dataset:** Visually rich documents paired with synthetic queries [generated by Daniel van Strien](https://huggingface.co/datasets/davanstrien/ufo-ColPali).
- **DocVQA Dataset:** A large set of document-derived Q&A pairs.

Each document was processed into 32x32 grids, generating both full-resolution and pooled embeddings. **Full-resolution** embeddings consisted of 1,030 vectors per page, while **pooled embeddings** included mean and max pooling variants.

All embeddings were were stored and kept in RAM to avoid caching effects during retrieval speed experiments.

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#experiment-setup)Experiment Setup

We evaluated retrieval quality with 1,000 queries. First, pooled embeddings retrieved the top 200 candidates. Then, full-resolution embeddings reranked them to produce the final top 20 results.

To measure performance, we used:

- **NDCG@20:** Measures ranking quality (how well the top results align with expectations).
- **Recall@20:** Measures the overlap between this method and the original ColPali retrieval.

## [](https://qdrant.tech/blog/colpali-qdrant-optimization/#results)Results

The experiment showed promising improvements in speed and accuracy. Retrieval time improved **13x** compared to using full-resolution embeddings alone.

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#metrics)Metrics

|Pooling Type|NDCG@20|Recall@20|
|---|---|---|
|**Mean**|0.952|0.917|
|**Max**|0.759|0.656|

Mean pooling preserved nearly identical quality to the original ColPali, with NDCG@20 = 0.952 and Recall@20 = 0.917. Max pooling did not perform well enough to be considered viable since it sacrificed significant accuracy without delivering a meaningful speed advantage.

## [](https://qdrant.tech/blog/colpali-qdrant-optimization/#whats-next)What’s Next?

Future experiments could push these results even further:

- Investigating column-wise pooling for additional compression.
- Testing half-precision (float16) vectors to balance memory use and speed.
- Skipping special multivectors during prefetch to streamline retrieval.
- Combining quantization with oversampling for even faster search.

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#try-it-yourself)Try It Yourself

Curious to see this in action? Explore the full codebase and experiment with ColPali optimizations:

- **Demo Notebook:** [GitHub Repository](https://github.com/qdrant/demo-colpali-optimized)
- **Webinar Walkthrough:** [Watch Here](https://www.youtube.com/live/_h6SN1WwnLs?si=n8gwiIjJ5dnfucXC)。">
<meta property="og:title" content="Optimizing ColPali for Retrieval at Scale, 13x Faster Results">
<meta property="og:description" content="
ColPali is a fascinating leap in document retrieval. Its precision in handling visually rich PDFs is phenomenal, but scaling it to handle real-world datasets comes with its share of computational challenges.

Here’s how we solved these challenges to make ColPali 13x faster without sacrificing the precision it’s known for.

## [](https://qdrant.tech/blog/colpali-qdrant-optimization/#the-scaling-dilemma)The Scaling Dilemma

ColPali generates **1,030 vectors for just one page of a PDF.** While this is manageable for small-scale tasks, in a real-world production setting where you may need to store hundreds od thousands of PDFs, the challenge of scaling becomes significant.

Consider this scenario:

- **Dataset Size:** 20,000 PDF pages.
- **Number of Vectors:** Each page generates ~1,000 vectors of 128 dimensions.

The total number of comparisons is calculated as:

1,000⋅1,000⋅20,000⋅128=2.56×1012 comparisons!

That’s trillions of comparisons needed to build the index. Even advanced indexing algorithms like **HNSW** struggle with this scale, as computational costs grow quadratically with amount of multivectors per page.

We turned to a hybrid optimization strategy combining **pooling** (to reduce computational overhead) and **reranking** (to preserve accuracy).

Before we go any deeper, watch our [Webinar video](https://www.youtube.com/live/_h6SN1WwnLs?si=n8gwiIjJ5dnfucXC) for the full demo walkthrough.

For those eager to explore, the [codebase is available here](https://github.com/qdrant/demo-colpali-optimized).

## [](https://qdrant.tech/blog/colpali-qdrant-optimization/#two-stage-retrieval-process)Two-Stage Retrieval Process

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#pooling)Pooling

Pooling is well-known in machine learning as a way to compress data while keeping important information. For ColPali, we reduced 1,030 vectors per page to just 38 vectors by pooling rows in the document’s 32x32 grid.

![](https://qdrant.tech/blog/colpali-optimization/rows.png)

Max and mean pooling are the two most popular types, so we decided to test both approaches on the rows of the grid. Likewise, we could apply pooling on columns, which we plan to explore in the future.

- **Mean Pooling:** Averages values across rows.
- **Max Pooling:** Selects the maximum value for each feature.

32 vectors represent the pooled rows, while 6 vectors encode contextual information derived from ColPali’s special tokens (e.g., for the beginning of the sequence, and task-specific instructions like “Describe the image”).

For our experiments, we chose to preserve these 6 additional vectors.

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#the-colpali-as-a-reranker-experiment)The “ColPali as a Reranker” Experiment

Pooling drastically reduces retrieval costs, but there’s a risk of losing fine-grained precision. To address this, we implemented a **two-stage retrieval system**, where embeddings generated with ColPali were max/mean pooled by grid rows to create lightweight vectors for the initial retrieval stage, followed by reranking with the original high-resolution embeddings:

1. **Pooled Retrieval:** Quickly retrieves the top 200 candidates using lightweight pooled embeddings.
2. **Full Reranking:** Refines these candidates using the original, high-resolution embeddings, delivering the final top 20 results.

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#implementation)Implementation

We created a custom dataset with over 20,000 unique PDF pages by merging:

- **ViDoRe Benchmark:** Designed for PDF documents retrieval evaluation.
- **UFO Dataset:** Visually rich documents paired with synthetic queries [generated by Daniel van Strien](https://huggingface.co/datasets/davanstrien/ufo-ColPali).
- **DocVQA Dataset:** A large set of document-derived Q&A pairs.

Each document was processed into 32x32 grids, generating both full-resolution and pooled embeddings. **Full-resolution** embeddings consisted of 1,030 vectors per page, while **pooled embeddings** included mean and max pooling variants.

All embeddings were were stored and kept in RAM to avoid caching effects during retrieval speed experiments.

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#experiment-setup)Experiment Setup

We evaluated retrieval quality with 1,000 queries. First, pooled embeddings retrieved the top 200 candidates. Then, full-resolution embeddings reranked them to produce the final top 20 results.

To measure performance, we used:

- **NDCG@20:** Measures ranking quality (how well the top results align with expectations).
- **Recall@20:** Measures the overlap between this method and the original ColPali retrieval.

## [](https://qdrant.tech/blog/colpali-qdrant-optimization/#results)Results

The experiment showed promising improvements in speed and accuracy. Retrieval time improved **13x** compared to using full-resolution embeddings alone.

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#metrics)Metrics

|Pooling Type|NDCG@20|Recall@20|
|---|---|---|
|**Mean**|0.952|0.917|
|**Max**|0.759|0.656|

Mean pooling preserved nearly identical quality to the original ColPali, with NDCG@20 = 0.952 and Recall@20 = 0.917. Max pooling did not perform well enough to be considered viable since it sacrificed significant accuracy without delivering a meaningful speed advantage.

## [](https://qdrant.tech/blog/colpali-qdrant-optimization/#whats-next)What’s Next?

Future experiments could push these results even further:

- Investigating column-wise pooling for additional compression.
- Testing half-precision (float16) vectors to balance memory use and speed.
- Skipping special multivectors during prefetch to streamline retrieval.
- Combining quantization with oversampling for even faster search.

### [](https://qdrant.tech/blog/colpali-qdrant-optimization/#try-it-yourself)Try It Yourself

Curious to see this in action? Explore the full codebase and experiment with ColPali optimizations:

- **Demo Notebook:** [GitHub Repository](https://github.com/qdrant/demo-colpali-optimized)
- **Webinar Walkthrough:** [Watch Here](https://www.youtube.com/live/_h6SN1WwnLs?si=n8gwiIjJ5dnfucXC)。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://winnerineast.github.io/post/Optimizing%20ColPali%20for%20Retrieval%20at%20Scale%2C%2013x%20Faster%20Results.html">
<meta property="og:image" content="https://github.githubassets.com/favicons/favicon.svg">
<title>Optimizing ColPali for Retrieval at Scale, 13x Faster Results</title>



</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}

</style>




<body>
    <div id="header">
<h1 class="postTitle">Optimizing ColPali for Retrieval at Scale, 13x Faster Results</h1>
<div class="title-right">
    <a href="https://winnerineast.github.io" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/winnerineast/winnerineast.github.io/issues/6" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><p>ColPali is a fascinating leap in document retrieval. Its precision in handling visually rich PDFs is phenomenal, but scaling it to handle real-world datasets comes with its share of computational challenges.</p>
<p>Here’s how we solved these challenges to make ColPali 13x faster without sacrificing the precision it’s known for.</p>
<h2><a href="https://qdrant.tech/blog/colpali-qdrant-optimization/#the-scaling-dilemma" rel="nofollow"></a>The Scaling Dilemma</h2>
<p>ColPali generates <strong>1,030 vectors for just one page of a PDF.</strong> While this is manageable for small-scale tasks, in a real-world production setting where you may need to store hundreds od thousands of PDFs, the challenge of scaling becomes significant.</p>
<p>Consider this scenario:</p>
<ul>
<li><strong>Dataset Size:</strong> 20,000 PDF pages.</li>
<li><strong>Number of Vectors:</strong> Each page generates ~1,000 vectors of 128 dimensions.</li>
</ul>
<p>The total number of comparisons is calculated as:</p>
<p>1,000⋅1,000⋅20,000⋅128=2.56×1012 comparisons!</p>
<p>That’s trillions of comparisons needed to build the index. Even advanced indexing algorithms like <strong>HNSW</strong> struggle with this scale, as computational costs grow quadratically with amount of multivectors per page.</p>
<p>We turned to a hybrid optimization strategy combining <strong>pooling</strong> (to reduce computational overhead) and <strong>reranking</strong> (to preserve accuracy).</p>
<p>Before we go any deeper, watch our <a href="https://www.youtube.com/live/_h6SN1WwnLs?si=n8gwiIjJ5dnfucXC" rel="nofollow">Webinar video</a> for the full demo walkthrough.</p>
<p>For those eager to explore, the <a href="https://github.com/qdrant/demo-colpali-optimized">codebase is available here</a>.</p>
<h2><a href="https://qdrant.tech/blog/colpali-qdrant-optimization/#two-stage-retrieval-process" rel="nofollow"></a>Two-Stage Retrieval Process</h2>
<h3><a href="https://qdrant.tech/blog/colpali-qdrant-optimization/#pooling" rel="nofollow"></a>Pooling</h3>
<p>Pooling is well-known in machine learning as a way to compress data while keeping important information. For ColPali, we reduced 1,030 vectors per page to just 38 vectors by pooling rows in the document’s 32x32 grid.</p>
<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/4b1efcac1ccc8878c810db9423d8c9acbdceb112a96fee6cb60eeeaff395aeed/68747470733a2f2f716472616e742e746563682f626c6f672f636f6c70616c692d6f7074696d697a6174696f6e2f726f77732e706e67"><img src="https://camo.githubusercontent.com/4b1efcac1ccc8878c810db9423d8c9acbdceb112a96fee6cb60eeeaff395aeed/68747470733a2f2f716472616e742e746563682f626c6f672f636f6c70616c692d6f7074696d697a6174696f6e2f726f77732e706e67" alt="" data-canonical-src="https://qdrant.tech/blog/colpali-optimization/rows.png" style="max-width: 100%;"></a></p>
<p>Max and mean pooling are the two most popular types, so we decided to test both approaches on the rows of the grid. Likewise, we could apply pooling on columns, which we plan to explore in the future.</p>
<ul>
<li><strong>Mean Pooling:</strong> Averages values across rows.</li>
<li><strong>Max Pooling:</strong> Selects the maximum value for each feature.</li>
</ul>
<p>32 vectors represent the pooled rows, while 6 vectors encode contextual information derived from ColPali’s special tokens (e.g., for the beginning of the sequence, and task-specific instructions like “Describe the image”).</p>
<p>For our experiments, we chose to preserve these 6 additional vectors.</p>
<h3><a href="https://qdrant.tech/blog/colpali-qdrant-optimization/#the-colpali-as-a-reranker-experiment" rel="nofollow"></a>The “ColPali as a Reranker” Experiment</h3>
<p>Pooling drastically reduces retrieval costs, but there’s a risk of losing fine-grained precision. To address this, we implemented a <strong>two-stage retrieval system</strong>, where embeddings generated with ColPali were max/mean pooled by grid rows to create lightweight vectors for the initial retrieval stage, followed by reranking with the original high-resolution embeddings:</p>
<ol>
<li><strong>Pooled Retrieval:</strong> Quickly retrieves the top 200 candidates using lightweight pooled embeddings.</li>
<li><strong>Full Reranking:</strong> Refines these candidates using the original, high-resolution embeddings, delivering the final top 20 results.</li>
</ol>
<h3><a href="https://qdrant.tech/blog/colpali-qdrant-optimization/#implementation" rel="nofollow"></a>Implementation</h3>
<p>We created a custom dataset with over 20,000 unique PDF pages by merging:</p>
<ul>
<li><strong>ViDoRe Benchmark:</strong> Designed for PDF documents retrieval evaluation.</li>
<li><strong>UFO Dataset:</strong> Visually rich documents paired with synthetic queries <a href="https://huggingface.co/datasets/davanstrien/ufo-ColPali" rel="nofollow">generated by Daniel van Strien</a>.</li>
<li><strong>DocVQA Dataset:</strong> A large set of document-derived Q&amp;A pairs.</li>
</ul>
<p>Each document was processed into 32x32 grids, generating both full-resolution and pooled embeddings. <strong>Full-resolution</strong> embeddings consisted of 1,030 vectors per page, while <strong>pooled embeddings</strong> included mean and max pooling variants.</p>
<p>All embeddings were were stored and kept in RAM to avoid caching effects during retrieval speed experiments.</p>
<h3><a href="https://qdrant.tech/blog/colpali-qdrant-optimization/#experiment-setup" rel="nofollow"></a>Experiment Setup</h3>
<p>We evaluated retrieval quality with 1,000 queries. First, pooled embeddings retrieved the top 200 candidates. Then, full-resolution embeddings reranked them to produce the final top 20 results.</p>
<p>To measure performance, we used:</p>
<ul>
<li><strong>NDCG@20:</strong> Measures ranking quality (how well the top results align with expectations).</li>
<li><strong>Recall@20:</strong> Measures the overlap between this method and the original ColPali retrieval.</li>
</ul>
<h2><a href="https://qdrant.tech/blog/colpali-qdrant-optimization/#results" rel="nofollow"></a>Results</h2>
<p>The experiment showed promising improvements in speed and accuracy. Retrieval time improved <strong>13x</strong> compared to using full-resolution embeddings alone.</p>
<h3><a href="https://qdrant.tech/blog/colpali-qdrant-optimization/#metrics" rel="nofollow"></a>Metrics</h3>
<markdown-accessiblity-table><table role="table">
<thead>
<tr>
<th>Pooling Type</th>
<th>NDCG@20</th>
<th>Recall@20</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Mean</strong></td>
<td>0.952</td>
<td>0.917</td>
</tr>
<tr>
<td><strong>Max</strong></td>
<td>0.759</td>
<td>0.656</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p>Mean pooling preserved nearly identical quality to the original ColPali, with NDCG@20 = 0.952 and Recall@20 = 0.917. Max pooling did not perform well enough to be considered viable since it sacrificed significant accuracy without delivering a meaningful speed advantage.</p>
<h2><a href="https://qdrant.tech/blog/colpali-qdrant-optimization/#whats-next" rel="nofollow"></a>What’s Next?</h2>
<p>Future experiments could push these results even further:</p>
<ul>
<li>Investigating column-wise pooling for additional compression.</li>
<li>Testing half-precision (float16) vectors to balance memory use and speed.</li>
<li>Skipping special multivectors during prefetch to streamline retrieval.</li>
<li>Combining quantization with oversampling for even faster search.</li>
</ul>
<h3><a href="https://qdrant.tech/blog/colpali-qdrant-optimization/#try-it-yourself" rel="nofollow"></a>Try It Yourself</h3>
<p>Curious to see this in action? Explore the full codebase and experiment with ColPali optimizations:</p>
<ul>
<li><strong>Demo Notebook:</strong> <a href="https://github.com/qdrant/demo-colpali-optimized">GitHub Repository</a></li>
<li><strong>Webinar Walkthrough:</strong> <a href="https://www.youtube.com/live/_h6SN1WwnLs?si=n8gwiIjJ5dnfucXC" rel="nofollow">Watch Here</a></li>
</ul></div>
<div style="font-size:small;margin-top:8px;float:right;"></div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://winnerineast.github.io">Winnerineast Blog</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if(""!=""){
    var startSite=new Date("");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","winnerineast/winnerineast.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}



</script>


</html>
